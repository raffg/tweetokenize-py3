<?xml version="1.0" encoding="ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>tweetokenize</title>
  <link rel="stylesheet" href="epydoc.css" type="text/css" />
  <script type="text/javascript" src="epydoc.js"></script>
</head>

<body bgcolor="white" text="black" link="blue" vlink="#204080"
      alink="#204080">
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th bgcolor="#70b0f0" class="navbar-select"
          >&nbsp;&nbsp;&nbsp;Home&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

      <th class="navbar" width="100%"></th>
  </tr>
</table>
<table width="100%" cellpadding="0" cellspacing="0">
  <tr valign="top">
    <td width="100%">
      <span class="breadcrumbs">
        Module&nbsp;tweetokenize
      </span>
    </td>
    <td>
      <table cellpadding="0" cellspacing="0">
        <!-- hide/show private -->
        <tr><td align="right"><span class="options"
            >[<a href="frames.html" target="_top">frames</a
            >]&nbsp;|&nbsp;<a href="tweetokenize-pysrc.html"
            target="_top">no&nbsp;frames</a>]</span></td></tr>
      </table>
    </td>
  </tr>
</table>
<h1 class="epydoc">Source Code for <a href="tweetokenize-module.html">Module tweetokenize</a></h1>
<pre class="py-src">
<a name="L1"></a><tt class="py-lineno">  1</tt>  <tt class="py-line"><tt class="py-comment">#!/usr/bin/env python</tt> </tt>
<a name="L2"></a><tt class="py-lineno">  2</tt>  <tt class="py-line"><tt class="py-comment"># -*- coding: utf-8 -*-</tt> </tt>
<a name="L3"></a><tt class="py-lineno">  3</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L4"></a><tt class="py-lineno">  4</tt>  <tt class="py-line"><tt class="py-comment"># Copyright: (c) 2013, Jared Suttles. All rights reserved.</tt> </tt>
<a name="L5"></a><tt class="py-lineno">  5</tt>  <tt class="py-line"><tt class="py-comment"># License: See LICENSE for details.</tt> </tt>
<a name="L6"></a><tt class="py-lineno">  6</tt>  <tt class="py-line"><tt class="py-comment"># - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - </tt> </tt>
<a name="L7"></a><tt class="py-lineno">  7</tt>  <tt class="py-line"> </tt>
<a name="L8"></a><tt class="py-lineno">  8</tt>  <tt class="py-line"><tt class="py-docstring">"""</tt> </tt>
<a name="L9"></a><tt class="py-lineno">  9</tt>  <tt class="py-line"><tt class="py-docstring">Tokenization and pre-processing for social media data used to train classifiers.</tt> </tt>
<a name="L10"></a><tt class="py-lineno"> 10</tt>  <tt class="py-line"><tt class="py-docstring">Focused on classification of sentiment, emotion, or mood.</tt> </tt>
<a name="L11"></a><tt class="py-lineno"> 11</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L12"></a><tt class="py-lineno"> 12</tt>  <tt class="py-line"><tt class="py-docstring">Intended as glue between Python wrappers for Twitter API and the Natural </tt> </tt>
<a name="L13"></a><tt class="py-lineno"> 13</tt>  <tt class="py-line"><tt class="py-docstring">Language Toolkit (NLTK), but probably applicable to tokenizing any short </tt> </tt>
<a name="L14"></a><tt class="py-lineno"> 14</tt>  <tt class="py-line"><tt class="py-docstring">messages of the social networking variety.</tt> </tt>
<a name="L15"></a><tt class="py-lineno"> 15</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L16"></a><tt class="py-lineno"> 16</tt>  <tt class="py-line"><tt class="py-docstring">In many cases, reducing feature-set complexity can increase performance of </tt> </tt>
<a name="L17"></a><tt class="py-lineno"> 17</tt>  <tt class="py-line"><tt class="py-docstring">classifiers trained for detecting sentiment. The available settings are based </tt> </tt>
<a name="L18"></a><tt class="py-lineno"> 18</tt>  <tt class="py-line"><tt class="py-docstring">on commonly modified and normalized features in classification research using </tt> </tt>
<a name="L19"></a><tt class="py-lineno"> 19</tt>  <tt class="py-line"><tt class="py-docstring">content from Twitter.</tt> </tt>
<a name="L20"></a><tt class="py-lineno"> 20</tt>  <tt class="py-line"><tt class="py-docstring">"""</tt> </tt>
<a name="L21"></a><tt class="py-lineno"> 21</tt>  <tt class="py-line"> </tt>
<a name="L22"></a><tt class="py-lineno"> 22</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">re</tt> </tt>
<a name="L23"></a><tt class="py-lineno"> 23</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">os</tt> <tt class="py-keyword">import</tt> <tt class="py-name">path</tt> </tt>
<a name="L24"></a><tt class="py-lineno"> 24</tt>  <tt class="py-line"><tt class="py-keyword">try</tt><tt class="py-op">:</tt> </tt>
<a name="L25"></a><tt class="py-lineno"> 25</tt>  <tt class="py-line">    <tt class="py-keyword">from</tt> <tt class="py-name">itertools</tt> <tt class="py-keyword">import</tt> <tt class="py-name">imap</tt> </tt>
<a name="L26"></a><tt class="py-lineno"> 26</tt>  <tt class="py-line"><tt class="py-keyword">except</tt> <tt class="py-name">ImportError</tt><tt class="py-op">:</tt> </tt>
<a name="L27"></a><tt class="py-lineno"> 27</tt>  <tt class="py-line">    <tt class="py-name">imap</tt> <tt class="py-op">=</tt> <tt class="py-name">map</tt> </tt>
<a name="L28"></a><tt class="py-lineno"> 28</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">htmlentitydefs</tt> <tt class="py-keyword">import</tt> <tt class="py-name">name2codepoint</tt> </tt>
<a name="L29"></a><tt class="py-lineno"> 29</tt>  <tt class="py-line"> </tt>
<a name="Tokenizer"></a><div id="Tokenizer-def"><a name="L30"></a><tt class="py-lineno"> 30</tt> <a class="py-toggle" href="#" id="Tokenizer-toggle" onclick="return toggle('Tokenizer');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html">Tokenizer</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="Tokenizer-expanded"><a name="L31"></a><tt class="py-lineno"> 31</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L32"></a><tt class="py-lineno"> 32</tt>  <tt class="py-line"><tt class="py-docstring">    Can be used to tokenize a string representation of a message, adjusting </tt> </tt>
<a name="L33"></a><tt class="py-lineno"> 33</tt>  <tt class="py-line"><tt class="py-docstring">    features based on the given configuration details, to enable further </tt> </tt>
<a name="L34"></a><tt class="py-lineno"> 34</tt>  <tt class="py-line"><tt class="py-docstring">    processing in feature extraction and training stages.</tt> </tt>
<a name="L35"></a><tt class="py-lineno"> 35</tt>  <tt class="py-line"><tt class="py-docstring">    </tt> </tt>
<a name="L36"></a><tt class="py-lineno"> 36</tt>  <tt class="py-line"><tt class="py-docstring">    An example usage::</tt> </tt>
<a name="L37"></a><tt class="py-lineno"> 37</tt>  <tt class="py-line"><tt class="py-docstring">    </tt> </tt>
<a name="L38"></a><tt class="py-lineno"> 38</tt>  <tt class="py-line"><tt class="py-docstring">      &gt;&gt;&gt; from tweetokenize import Tokenizer</tt> </tt>
<a name="L39"></a><tt class="py-lineno"> 39</tt>  <tt class="py-line"><tt class="py-docstring">      &gt;&gt;&gt; gettokens = Tokenizer(usernames='USER', urls='')</tt> </tt>
<a name="L40"></a><tt class="py-lineno"> 40</tt>  <tt class="py-line"><tt class="py-docstring">      &gt;&gt;&gt; gettokens.tokenize('@justinbeiber yo man!love you#inlove#wantyou in a totally straight way #brotime &lt;3:p:D www.justinbeiber.com')</tt> </tt>
<a name="L41"></a><tt class="py-lineno"> 41</tt>  <tt class="py-line"><tt class="py-docstring">      [u'USER', u'yo', u'man', u'!', u'love', u'you', u'#inlove', u'#wantyou', u'in', u'a', u'totally', u'straight', u'way', u'#brotime', u'&lt;3', u':p', u':D']</tt> </tt>
<a name="L42"></a><tt class="py-lineno"> 42</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="Tokenizer.TokenizerException"></a><div id="Tokenizer.TokenizerException-def"><a name="L43"></a><tt class="py-lineno"> 43</tt> <a class="py-toggle" href="#" id="Tokenizer.TokenizerException-toggle" onclick="return toggle('Tokenizer.TokenizerException');">-</a><tt class="py-line">    <tt class="py-keyword">class</tt> <a class="py-def-name" href="tweetokenize.Tokenizer.TokenizerException-class.html">TokenizerException</a><tt class="py-op">(</tt><tt class="py-base-class">BaseException</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> <tt class="py-keyword">pass</tt> </tt>
</div><a name="L44"></a><tt class="py-lineno"> 44</tt>  <tt class="py-line">    <tt id="link-0" class="py-name" targets="Variable tweetokenize.Tokenizer.html_entities=tweetokenize.Tokenizer-class.html#html_entities"><a title="tweetokenize.Tokenizer.html_entities" class="py-name" href="#" onclick="return doclink('link-0', 'html_entities', 'link-0');">html_entities</a></tt> <tt class="py-op">=</tt> <tt class="py-op">{</tt><tt class="py-name">k</tt><tt class="py-op">:</tt><tt class="py-name">unichr</tt><tt class="py-op">(</tt><tt class="py-name">v</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">k</tt><tt class="py-op">,</tt><tt class="py-name">v</tt> <tt class="py-keyword">in</tt> <tt class="py-name">name2codepoint</tt><tt class="py-op">.</tt><tt class="py-name">items</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">}</tt> </tt>
<a name="L45"></a><tt class="py-lineno"> 45</tt>  <tt class="py-line">    <tt id="link-1" class="py-name" targets="Variable tweetokenize.Tokenizer.__default_args=tweetokenize.Tokenizer-class.html#__default_args"><a title="tweetokenize.Tokenizer.__default_args" class="py-name" href="#" onclick="return doclink('link-1', '__default_args', 'link-1');">__default_args</a></tt> <tt class="py-op">=</tt> <tt class="py-name">None</tt> </tt>
<a name="L46"></a><tt class="py-lineno"> 46</tt>  <tt class="py-line">     </tt>
<a name="L47"></a><tt class="py-lineno"> 47</tt>  <tt class="py-line">    <tt class="py-comment"># Regular expressions</tt> </tt>
<a name="L48"></a><tt class="py-lineno"> 48</tt>  <tt class="py-line">    <tt id="link-2" class="py-name" targets="Variable tweetokenize.Tokenizer.usernames_re=tweetokenize.Tokenizer-class.html#usernames_re"><a title="tweetokenize.Tokenizer.usernames_re" class="py-name" href="#" onclick="return doclink('link-2', 'usernames_re', 'link-2');">usernames_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">r"@\w{1,15}"</tt><tt class="py-op">)</tt> </tt>
<a name="L49"></a><tt class="py-lineno"> 49</tt>  <tt class="py-line">    <tt id="link-3" class="py-name" targets="Variable tweetokenize.Tokenizer._topleveldomains=tweetokenize.Tokenizer-class.html#_topleveldomains"><a title="tweetokenize.Tokenizer._topleveldomains" class="py-name" href="#" onclick="return doclink('link-3', '_topleveldomains', 'link-3');">_topleveldomains</a></tt> <tt class="py-op">=</tt> <tt class="py-string">'museum|travel|aero|arpa|asia|coop|info|jobs|mobi|name|post|biz|cat|com|edu|gov|int|mil|net|org|pro|tel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cu|cv|cw|cx|cy|cz|de|dj|dk|dm|do|dz|ec|ee|eg|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|sk|sl|sm|sn|so|sr|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|za|zm|zw'</tt> </tt>
<a name="L50"></a><tt class="py-lineno"> 50</tt>  <tt class="py-line">    <tt id="link-4" class="py-name" targets="Variable tweetokenize.Tokenizer.urls_re=tweetokenize.Tokenizer-class.html#urls_re"><a title="tweetokenize.Tokenizer.urls_re" class="py-name" href="#" onclick="return doclink('link-4', 'urls_re', 'link-4');">urls_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">r"(?:(?:https?\://[A-Za-z0-9\.]+)|(?:(?:www\.)?[A-Za-z0-9]+\.(?:%s)))(?:\/\S+)?(?=\s+|$)"</tt> <tt class="py-op">%</tt> <tt id="link-5" class="py-name"><a title="tweetokenize.Tokenizer._topleveldomains" class="py-name" href="#" onclick="return doclink('link-5', '_topleveldomains', 'link-3');">_topleveldomains</a></tt><tt class="py-op">)</tt> </tt>
<a name="L51"></a><tt class="py-lineno"> 51</tt>  <tt class="py-line">    <tt id="link-6" class="py-name" targets="Variable tweetokenize.Tokenizer.hashtags_re=tweetokenize.Tokenizer-class.html#hashtags_re"><a title="tweetokenize.Tokenizer.hashtags_re" class="py-name" href="#" onclick="return doclink('link-6', 'hashtags_re', 'link-6');">hashtags_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">r"#\w+[\w'-]*\w+"</tt><tt class="py-op">)</tt> </tt>
<a name="L52"></a><tt class="py-lineno"> 52</tt>  <tt class="py-line">    <tt id="link-7" class="py-name" targets="Variable tweetokenize.Tokenizer.ellipsis_re=tweetokenize.Tokenizer-class.html#ellipsis_re"><a title="tweetokenize.Tokenizer.ellipsis_re" class="py-name" href="#" onclick="return doclink('link-7', 'ellipsis_re', 'link-7');">ellipsis_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">r"\.\.+"</tt><tt class="py-op">)</tt> </tt>
<a name="L53"></a><tt class="py-lineno"> 53</tt>  <tt class="py-line">    <tt id="link-8" class="py-name" targets="Variable tweetokenize.Tokenizer.word_re=tweetokenize.Tokenizer-class.html#word_re"><a title="tweetokenize.Tokenizer.word_re" class="py-name" href="#" onclick="return doclink('link-8', 'word_re', 'link-8');">word_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">r"(?:[a-zA-Z0-9]+['-]?[a-zA-Z]+[a-zA-Z0-9]*)|(?:[a-zA-Z0-9]*[a-zA-Z]+['-]?[a-zA-Z0-9]+)"</tt><tt class="py-op">)</tt> </tt>
<a name="L54"></a><tt class="py-lineno"> 54</tt>  <tt class="py-line">    <tt id="link-9" class="py-name" targets="Variable tweetokenize.Tokenizer.times_re=tweetokenize.Tokenizer-class.html#times_re"><a title="tweetokenize.Tokenizer.times_re" class="py-name" href="#" onclick="return doclink('link-9', 'times_re', 'link-9');">times_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">r"\d{1,2}:\d{2}(?::\d{2})?\s*(?:AM|PM|am|pm)?"</tt><tt class="py-op">)</tt> </tt>
<a name="L55"></a><tt class="py-lineno"> 55</tt>  <tt class="py-line">    <tt id="link-10" class="py-name" targets="Variable tweetokenize.Tokenizer.phonenumbers_re=tweetokenize.Tokenizer-class.html#phonenumbers_re"><a title="tweetokenize.Tokenizer.phonenumbers_re" class="py-name" href="#" onclick="return doclink('link-10', 'phonenumbers_re', 'link-10');">phonenumbers_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">r"(?:\+?[01][\-\s\.]*)?(?:\(?\d{3}[\-\s\.\)]*)?\d{3}[\-\s\.]*\d{4}(?:\s*x\s*\d+)?(?=\s+|$)"</tt><tt class="py-op">)</tt> </tt>
<a name="L56"></a><tt class="py-lineno"> 56</tt>  <tt class="py-line">    <tt id="link-11" class="py-name" targets="Variable tweetokenize.Tokenizer._number=tweetokenize.Tokenizer-class.html#_number"><a title="tweetokenize.Tokenizer._number" class="py-name" href="#" onclick="return doclink('link-11', '_number', 'link-11');">_number</a></tt> <tt class="py-op">=</tt> <tt class="py-string">r"(?:[+-]?\$?\d+(?:\.\d+)?(?:[eE]-?\d+)?%?)(?![A-Za-z])"</tt> </tt>
<a name="L57"></a><tt class="py-lineno"> 57</tt>  <tt class="py-line">    <tt id="link-12" class="py-name" targets="Variable tweetokenize.Tokenizer.numbers_re=tweetokenize.Tokenizer-class.html#numbers_re"><a title="tweetokenize.Tokenizer.numbers_re" class="py-name" href="#" onclick="return doclink('link-12', 'numbers_re', 'link-12');">numbers_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">r"%(num)s(?:\s*/\s*%(num)s)?"</tt> <tt class="py-op">%</tt> <tt class="py-op">{</tt><tt class="py-string">'num'</tt><tt class="py-op">:</tt> <tt id="link-13" class="py-name"><a title="tweetokenize.Tokenizer._number" class="py-name" href="#" onclick="return doclink('link-13', '_number', 'link-11');">_number</a></tt><tt class="py-op">}</tt><tt class="py-op">)</tt> <tt class="py-comment"># deals with fractions</tt> </tt>
<a name="L58"></a><tt class="py-lineno"> 58</tt>  <tt class="py-line">    <tt id="link-14" class="py-name" targets="Variable tweetokenize.Tokenizer.other_re=tweetokenize.Tokenizer-class.html#other_re"><a title="tweetokenize.Tokenizer.other_re" class="py-name" href="#" onclick="return doclink('link-14', 'other_re', 'link-14');">other_re</a></tt> <tt class="py-op">=</tt> <tt class="py-string">r"(?:[^#\s\.]|\.(?!\.))+"</tt> </tt>
<a name="L59"></a><tt class="py-lineno"> 59</tt>  <tt class="py-line">    <tt id="link-15" class="py-name" targets="Variable tweetokenize.Tokenizer._token_regexs=tweetokenize.Tokenizer-class.html#_token_regexs"><a title="tweetokenize.Tokenizer._token_regexs" class="py-name" href="#" onclick="return doclink('link-15', '_token_regexs', 'link-15');">_token_regexs</a></tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-string">'usernames'</tt><tt class="py-op">,</tt> <tt class="py-string">'urls'</tt><tt class="py-op">,</tt> <tt class="py-string">'hashtags'</tt><tt class="py-op">,</tt> <tt class="py-string">'times'</tt><tt class="py-op">,</tt> <tt class="py-string">'phonenumbers'</tt><tt class="py-op">,</tt> <tt class="py-string">'numbers'</tt><tt class="py-op">)</tt> </tt>
<a name="L60"></a><tt class="py-lineno"> 60</tt>  <tt class="py-line">    <tt id="link-16" class="py-name" targets="Variable tweetokenize.Tokenizer.tokenize_re=tweetokenize.Tokenizer-class.html#tokenize_re"><a title="tweetokenize.Tokenizer.tokenize_re" class="py-name" href="#" onclick="return doclink('link-16', 'tokenize_re', 'link-16');">tokenize_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">ur"|"</tt><tt class="py-op">.</tt><tt class="py-name">join</tt><tt class="py-op">(</tt><tt class="py-name">imap</tt><tt class="py-op">(</tt><tt class="py-keyword">lambda</tt> <tt class="py-name">x</tt><tt class="py-op">:</tt> <tt class="py-name">getattr</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">,</tt> <tt class="py-string">'pattern'</tt><tt class="py-op">,</tt> <tt class="py-name">x</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L61"></a><tt class="py-lineno"> 61</tt>  <tt class="py-line">        <tt class="py-op">[</tt><tt class="py-name">locals</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">[</tt><tt class="py-string">'%s_re'</tt> <tt class="py-op">%</tt> <tt class="py-name">regex</tt><tt class="py-op">]</tt> <tt class="py-keyword">for</tt> <tt class="py-name">regex</tt> <tt class="py-keyword">in</tt> <tt id="link-17" class="py-name"><a title="tweetokenize.Tokenizer._token_regexs" class="py-name" href="#" onclick="return doclink('link-17', '_token_regexs', 'link-15');">_token_regexs</a></tt><tt class="py-op">]</tt> <tt class="py-op">+</tt> <tt class="py-op">[</tt><tt id="link-18" class="py-name"><a title="tweetokenize.Tokenizer.word_re" class="py-name" href="#" onclick="return doclink('link-18', 'word_re', 'link-8');">word_re</a></tt><tt class="py-op">,</tt> <tt id="link-19" class="py-name"><a title="tweetokenize.Tokenizer.ellipsis_re" class="py-name" href="#" onclick="return doclink('link-19', 'ellipsis_re', 'link-7');">ellipsis_re</a></tt><tt class="py-op">,</tt> <tt id="link-20" class="py-name"><a title="tweetokenize.Tokenizer.other_re" class="py-name" href="#" onclick="return doclink('link-20', 'other_re', 'link-14');">other_re</a></tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">;</tt> <tt class="py-keyword">del</tt> <tt class="py-name">regex</tt> </tt>
<a name="L62"></a><tt class="py-lineno"> 62</tt>  <tt class="py-line">    <tt id="link-21" class="py-name" targets="Variable tweetokenize.Tokenizer.html_entities_re=tweetokenize.Tokenizer-class.html#html_entities_re"><a title="tweetokenize.Tokenizer.html_entities_re" class="py-name" href="#" onclick="return doclink('link-21', 'html_entities_re', 'link-21');">html_entities_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">r"&amp;#?\w+;"</tt><tt class="py-op">)</tt> </tt>
<a name="L63"></a><tt class="py-lineno"> 63</tt>  <tt class="py-line">    <tt id="link-22" class="py-name" targets="Variable tweetokenize.Tokenizer.repeating_re=tweetokenize.Tokenizer-class.html#repeating_re"><a title="tweetokenize.Tokenizer.repeating_re" class="py-name" href="#" onclick="return doclink('link-22', 'repeating_re', 'link-22');">repeating_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">r"([a-zA-Z])\1\1+"</tt><tt class="py-op">)</tt> </tt>
<a name="L64"></a><tt class="py-lineno"> 64</tt>  <tt class="py-line">    <tt id="link-23" class="py-name" targets="Variable tweetokenize.Tokenizer._doublequotes=tweetokenize.Tokenizer-class.html#_doublequotes"><a title="tweetokenize.Tokenizer._doublequotes" class="py-name" href="#" onclick="return doclink('link-23', '_doublequotes', 'link-23');">_doublequotes</a></tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-string">u'&#8220;'</tt><tt class="py-op">,</tt><tt class="py-string">u'&#8221;'</tt><tt class="py-op">)</tt><tt class="py-op">,</tt><tt class="py-op">(</tt><tt class="py-string">u'"'</tt><tt class="py-op">,</tt><tt class="py-string">u'"'</tt><tt class="py-op">)</tt><tt class="py-op">,</tt><tt class="py-op">(</tt><tt class="py-string">u'&#8216;'</tt><tt class="py-op">,</tt><tt class="py-string">u'&#8217;'</tt><tt class="py-op">)</tt><tt class="py-op">,</tt><tt class="py-op">(</tt><tt class="py-string">u'&#65282;'</tt><tt class="py-op">,</tt><tt class="py-string">u'&#65282;'</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L65"></a><tt class="py-lineno"> 65</tt>  <tt class="py-line">    <tt id="link-24" class="py-name" targets="Variable tweetokenize.Tokenizer.punctuation=tweetokenize.Tokenizer-class.html#punctuation"><a title="tweetokenize.Tokenizer.punctuation" class="py-name" href="#" onclick="return doclink('link-24', 'punctuation', 'link-24');">punctuation</a></tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-string">u'!$%()*+,-/:;&lt;=&gt;?[\\]^_.`{|}~\''</tt> <tt class="py-op">+</tt> <tt class="py-string">u''</tt><tt class="py-op">.</tt><tt class="py-name">join</tt><tt class="py-op">(</tt><tt class="py-name">c</tt> <tt class="py-keyword">for</tt> <tt class="py-name">t</tt> <tt class="py-keyword">in</tt> <tt id="link-25" class="py-name"><a title="tweetokenize.Tokenizer._doublequotes" class="py-name" href="#" onclick="return doclink('link-25', '_doublequotes', 'link-23');">_doublequotes</a></tt> <tt class="py-keyword">for</tt> <tt class="py-name">c</tt> <tt class="py-keyword">in</tt> <tt class="py-name">t</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L66"></a><tt class="py-lineno"> 66</tt>  <tt class="py-line">    <tt id="link-26" class="py-name" targets="Variable tweetokenize.Tokenizer.quotes_re=tweetokenize.Tokenizer-class.html#quotes_re"><a title="tweetokenize.Tokenizer.quotes_re" class="py-name" href="#" onclick="return doclink('link-26', 'quotes_re', 'link-26');">quotes_re</a></tt> <tt class="py-op">=</tt> <tt class="py-name">re</tt><tt class="py-op">.</tt><tt class="py-name">compile</tt><tt class="py-op">(</tt><tt class="py-string">ur"|"</tt><tt class="py-op">.</tt><tt class="py-name">join</tt><tt class="py-op">(</tt><tt class="py-string">ur'(%s.*?%s)'</tt> <tt class="py-op">%</tt> <tt class="py-name">t</tt> <tt class="py-keyword">for</tt> <tt class="py-name">t</tt> <tt class="py-keyword">in</tt> <tt id="link-27" class="py-name"><a title="tweetokenize.Tokenizer._doublequotes" class="py-name" href="#" onclick="return doclink('link-27', '_doublequotes', 'link-23');">_doublequotes</a></tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-string">ur'|\s(\'.*?\')\s'</tt><tt class="py-op">)</tt> </tt>
<a name="L67"></a><tt class="py-lineno"> 67</tt>  <tt class="py-line">    <tt class="py-comment">#emoji_re = re.compile(ur'[\U0001f300-\U0001f5ff....</tt> </tt>
<a name="L68"></a><tt class="py-lineno"> 68</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer.__init__"></a><div id="Tokenizer.__init__-def"><a name="L69"></a><tt class="py-lineno"> 69</tt> <a class="py-toggle" href="#" id="Tokenizer.__init__-toggle" onclick="return toggle('Tokenizer.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">lowercase</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">,</tt> <tt class="py-param">allcapskeep</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">,</tt> <tt class="py-param">normalize</tt><tt class="py-op">=</tt><tt class="py-number">3</tt><tt class="py-op">,</tt> </tt>
<a name="L70"></a><tt class="py-lineno"> 70</tt>  <tt class="py-line">                 <tt class="py-param">usernames</tt><tt class="py-op">=</tt><tt class="py-string">'USERNAME'</tt><tt class="py-op">,</tt> <tt class="py-param">urls</tt><tt class="py-op">=</tt><tt class="py-string">'URL'</tt><tt class="py-op">,</tt> <tt class="py-param">hashtags</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">,</tt> </tt>
<a name="L71"></a><tt class="py-lineno"> 71</tt>  <tt class="py-line">                 <tt class="py-param">phonenumbers</tt><tt class="py-op">=</tt><tt class="py-string">'PHONENUMBER'</tt><tt class="py-op">,</tt> <tt class="py-param">times</tt><tt class="py-op">=</tt><tt class="py-string">'TIME'</tt><tt class="py-op">,</tt> <tt class="py-param">numbers</tt><tt class="py-op">=</tt><tt class="py-string">'NUMBER'</tt><tt class="py-op">,</tt> </tt>
<a name="L72"></a><tt class="py-lineno"> 72</tt>  <tt class="py-line">                 <tt class="py-param">ignorequotes</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">,</tt> <tt class="py-param">ignorestopwords</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer.__init__-expanded"><a name="L73"></a><tt class="py-lineno"> 73</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L74"></a><tt class="py-lineno"> 74</tt>  <tt class="py-line"><tt class="py-docstring">        Constructs a new Tokenizer. Can specify custom settings for various </tt> </tt>
<a name="L75"></a><tt class="py-lineno"> 75</tt>  <tt class="py-line"><tt class="py-docstring">        feature normalizations.</tt> </tt>
<a name="L76"></a><tt class="py-lineno"> 76</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L77"></a><tt class="py-lineno"> 77</tt>  <tt class="py-line"><tt class="py-docstring">        Any features with replacement tokens can be removed from the message by </tt> </tt>
<a name="L78"></a><tt class="py-lineno"> 78</tt>  <tt class="py-line"><tt class="py-docstring">        setting the token to the empty string (C{""}), C{"DELETE"}, or </tt> </tt>
<a name="L79"></a><tt class="py-lineno"> 79</tt>  <tt class="py-line"><tt class="py-docstring">        C{"REMOVE"}.</tt> </tt>
<a name="L80"></a><tt class="py-lineno"> 80</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L81"></a><tt class="py-lineno"> 81</tt>  <tt class="py-line"><tt class="py-docstring">        @type lowercase: C{bool}</tt> </tt>
<a name="L82"></a><tt class="py-lineno"> 82</tt>  <tt class="py-line"><tt class="py-docstring">        @param lowercase: If C{True}, lowercases words, excluding those with </tt> </tt>
<a name="L83"></a><tt class="py-lineno"> 83</tt>  <tt class="py-line"><tt class="py-docstring">            all letters capitalized.</tt> </tt>
<a name="L84"></a><tt class="py-lineno"> 84</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L85"></a><tt class="py-lineno"> 85</tt>  <tt class="py-line"><tt class="py-docstring">        @type allcapskeep: C{bool}</tt> </tt>
<a name="L86"></a><tt class="py-lineno"> 86</tt>  <tt class="py-line"><tt class="py-docstring">        @param allcapskeep: If C{True}, maintains capitalization for words with </tt> </tt>
<a name="L87"></a><tt class="py-lineno"> 87</tt>  <tt class="py-line"><tt class="py-docstring">            all letters in capitals. Otherwise, capitalization for such words </tt> </tt>
<a name="L88"></a><tt class="py-lineno"> 88</tt>  <tt class="py-line"><tt class="py-docstring">            is dependent on C{lowercase}.</tt> </tt>
<a name="L89"></a><tt class="py-lineno"> 89</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L90"></a><tt class="py-lineno"> 90</tt>  <tt class="py-line"><tt class="py-docstring">        @type normalize: C{int}</tt> </tt>
<a name="L91"></a><tt class="py-lineno"> 91</tt>  <tt class="py-line"><tt class="py-docstring">        @param normalize: The number of repeating letters when normalizing </tt> </tt>
<a name="L92"></a><tt class="py-lineno"> 92</tt>  <tt class="py-line"><tt class="py-docstring">            arbitrary letter elongations.</tt> </tt>
<a name="L93"></a><tt class="py-lineno"> 93</tt>  <tt class="py-line"><tt class="py-docstring">            </tt> </tt>
<a name="L94"></a><tt class="py-lineno"> 94</tt>  <tt class="py-line"><tt class="py-docstring">            Example::</tt> </tt>
<a name="L95"></a><tt class="py-lineno"> 95</tt>  <tt class="py-line"><tt class="py-docstring">                Heyyyyyy i lovvvvvvve youuuuuuuuu &lt;3</tt> </tt>
<a name="L96"></a><tt class="py-lineno"> 96</tt>  <tt class="py-line"><tt class="py-docstring">            </tt> </tt>
<a name="L97"></a><tt class="py-lineno"> 97</tt>  <tt class="py-line"><tt class="py-docstring">            Becomes::</tt> </tt>
<a name="L98"></a><tt class="py-lineno"> 98</tt>  <tt class="py-line"><tt class="py-docstring">                Heyyy i lovvve youuu &lt;3</tt> </tt>
<a name="L99"></a><tt class="py-lineno"> 99</tt>  <tt class="py-line"><tt class="py-docstring">            </tt> </tt>
<a name="L100"></a><tt class="py-lineno">100</tt>  <tt class="py-line"><tt class="py-docstring">            Not sure why you would want to change this (maybe just for fun?? :P)</tt> </tt>
<a name="L101"></a><tt class="py-lineno">101</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L102"></a><tt class="py-lineno">102</tt>  <tt class="py-line"><tt class="py-docstring">        @param usernames: Serves as the replacement token for anything that </tt> </tt>
<a name="L103"></a><tt class="py-lineno">103</tt>  <tt class="py-line"><tt class="py-docstring">            parses as a Twitter username, ie. C{@rayj}. Setting this to </tt> </tt>
<a name="L104"></a><tt class="py-lineno">104</tt>  <tt class="py-line"><tt class="py-docstring">            C{False} means no usernames will be changed.</tt> </tt>
<a name="L105"></a><tt class="py-lineno">105</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L106"></a><tt class="py-lineno">106</tt>  <tt class="py-line"><tt class="py-docstring">        @param urls: Serves as the replacement token for anything that </tt> </tt>
<a name="L107"></a><tt class="py-lineno">107</tt>  <tt class="py-line"><tt class="py-docstring">            parses as a URL, ie. C{bit.ly} or C{http://example.com}. Setting </tt> </tt>
<a name="L108"></a><tt class="py-lineno">108</tt>  <tt class="py-line"><tt class="py-docstring">            this to C{False} means no URLs will be changed.</tt> </tt>
<a name="L109"></a><tt class="py-lineno">109</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L110"></a><tt class="py-lineno">110</tt>  <tt class="py-line"><tt class="py-docstring">        @param hashtags: Serves as the replacement token for anything that </tt> </tt>
<a name="L111"></a><tt class="py-lineno">111</tt>  <tt class="py-line"><tt class="py-docstring">            parses as a Twitter hashtag, ie. C{#ihititfirst} or </tt> </tt>
<a name="L112"></a><tt class="py-lineno">112</tt>  <tt class="py-line"><tt class="py-docstring">            C{#onedirection}. Setting this to C{False} means no hashtags will </tt> </tt>
<a name="L113"></a><tt class="py-lineno">113</tt>  <tt class="py-line"><tt class="py-docstring">            be changed.</tt> </tt>
<a name="L114"></a><tt class="py-lineno">114</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L115"></a><tt class="py-lineno">115</tt>  <tt class="py-line"><tt class="py-docstring">        @param phonenumbers: Replacement token for phone numbers.</tt> </tt>
<a name="L116"></a><tt class="py-lineno">116</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L117"></a><tt class="py-lineno">117</tt>  <tt class="py-line"><tt class="py-docstring">        @param times: Replacement token for times.</tt> </tt>
<a name="L118"></a><tt class="py-lineno">118</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L119"></a><tt class="py-lineno">119</tt>  <tt class="py-line"><tt class="py-docstring">        @param numbers: Replacement token for any other kinds of numbers.</tt> </tt>
<a name="L120"></a><tt class="py-lineno">120</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L121"></a><tt class="py-lineno">121</tt>  <tt class="py-line"><tt class="py-docstring">        @type ignorequotes: C{bool}</tt> </tt>
<a name="L122"></a><tt class="py-lineno">122</tt>  <tt class="py-line"><tt class="py-docstring">        @param ignorequotes: If C{True}, will remove various types of quotes </tt> </tt>
<a name="L123"></a><tt class="py-lineno">123</tt>  <tt class="py-line"><tt class="py-docstring">            and the contents within.</tt> </tt>
<a name="L124"></a><tt class="py-lineno">124</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L125"></a><tt class="py-lineno">125</tt>  <tt class="py-line"><tt class="py-docstring">        @type ignorestopwords: C{bool}</tt> </tt>
<a name="L126"></a><tt class="py-lineno">126</tt>  <tt class="py-line"><tt class="py-docstring">        @param ignorestopwords: If C{True}, will remove any stopwords. The </tt> </tt>
<a name="L127"></a><tt class="py-lineno">127</tt>  <tt class="py-line"><tt class="py-docstring">            default set includes 'I', 'me', 'itself', 'against', 'should', etc.</tt> </tt>
<a name="L128"></a><tt class="py-lineno">128</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L129"></a><tt class="py-lineno">129</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt id="link-28" class="py-name" targets="Class tweetokenize.Tokenizer=tweetokenize.Tokenizer-class.html"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-28', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-29" class="py-name"><a title="tweetokenize.Tokenizer.__default_args" class="py-name" href="#" onclick="return doclink('link-29', '__default_args', 'link-1');">__default_args</a></tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L130"></a><tt class="py-lineno">130</tt>  <tt class="py-line">            <tt id="link-30" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-30', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-31" class="py-name"><a title="tweetokenize.Tokenizer.__default_args" class="py-name" href="#" onclick="return doclink('link-31', '__default_args', 'link-1');">__default_args</a></tt> <tt class="py-op">=</tt> <tt class="py-name">locals</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">keys</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L131"></a><tt class="py-lineno">131</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">keyword</tt><tt class="py-op">,</tt> <tt class="py-name">value</tt> <tt class="py-keyword">in</tt> <tt class="py-name">locals</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">items</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L132"></a><tt class="py-lineno">132</tt>  <tt class="py-line">            <tt class="py-name">setattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">keyword</tt><tt class="py-op">,</tt> <tt class="py-name">value</tt><tt class="py-op">)</tt> </tt>
<a name="L133"></a><tt class="py-lineno">133</tt>  <tt class="py-line">        <tt class="py-name">lexicons</tt> <tt class="py-op">=</tt> <tt class="py-name">path</tt><tt class="py-op">.</tt><tt class="py-name">dirname</tt><tt class="py-op">(</tt><tt class="py-name">path</tt><tt class="py-op">.</tt><tt class="py-name">realpath</tt><tt class="py-op">(</tt><tt class="py-name">__file__</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-string">'/lexicons/%s.txt'</tt> </tt>
<a name="L134"></a><tt class="py-lineno">134</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-32" class="py-name" targets="Method tweetokenize.Tokenizer.emoticons()=tweetokenize.Tokenizer-class.html#emoticons"><a title="tweetokenize.Tokenizer.emoticons" class="py-name" href="#" onclick="return doclink('link-32', 'emoticons', 'link-32');">emoticons</a></tt><tt class="py-op">(</tt><tt class="py-name">filename</tt><tt class="py-op">=</tt><tt class="py-name">lexicons</tt> <tt class="py-op">%</tt> <tt class="py-string">'emoticons'</tt><tt class="py-op">)</tt> </tt>
<a name="L135"></a><tt class="py-lineno">135</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-33" class="py-name" targets="Method tweetokenize.Tokenizer.stopwords()=tweetokenize.Tokenizer-class.html#stopwords"><a title="tweetokenize.Tokenizer.stopwords" class="py-name" href="#" onclick="return doclink('link-33', 'stopwords', 'link-33');">stopwords</a></tt><tt class="py-op">(</tt><tt class="py-name">filename</tt><tt class="py-op">=</tt><tt class="py-name">lexicons</tt> <tt class="py-op">%</tt> <tt class="py-string">'stopwords'</tt><tt class="py-op">)</tt> </tt>
</div><a name="L136"></a><tt class="py-lineno">136</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer.__call__"></a><div id="Tokenizer.__call__-def"><a name="L137"></a><tt class="py-lineno">137</tt> <a class="py-toggle" href="#" id="Tokenizer.__call__-toggle" onclick="return toggle('Tokenizer.__call__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#__call__">__call__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">iterable</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer.__call__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer.__call__-expanded"><a name="L138"></a><tt class="py-lineno">138</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L139"></a><tt class="py-lineno">139</tt>  <tt class="py-line"><tt class="py-docstring">        Iterator for the tokenization of given messages.</tt> </tt>
<a name="L140"></a><tt class="py-lineno">140</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L141"></a><tt class="py-lineno">141</tt>  <tt class="py-line"><tt class="py-docstring">        @rtype: C{list} of C{str}</tt> </tt>
<a name="L142"></a><tt class="py-lineno">142</tt>  <tt class="py-line"><tt class="py-docstring">        @return: Iterator of lists representing message tokenizations.</tt> </tt>
<a name="L143"></a><tt class="py-lineno">143</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L144"></a><tt class="py-lineno">144</tt>  <tt class="py-line"><tt class="py-docstring">        @param iterable: Object capable of iteration, providing strings for </tt> </tt>
<a name="L145"></a><tt class="py-lineno">145</tt>  <tt class="py-line"><tt class="py-docstring">            tokenization.</tt> </tt>
<a name="L146"></a><tt class="py-lineno">146</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L147"></a><tt class="py-lineno">147</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">msg</tt> <tt class="py-keyword">in</tt> <tt class="py-name">iterable</tt><tt class="py-op">:</tt> </tt>
<a name="L148"></a><tt class="py-lineno">148</tt>  <tt class="py-line">            <tt class="py-keyword">yield</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-34" class="py-name" targets="Method tweetokenize.Tokenizer.tokenize()=tweetokenize.Tokenizer-class.html#tokenize"><a title="tweetokenize.Tokenizer.tokenize" class="py-name" href="#" onclick="return doclink('link-34', 'tokenize', 'link-34');">tokenize</a></tt><tt class="py-op">(</tt><tt class="py-name">msg</tt><tt class="py-op">)</tt> </tt>
</div><a name="L149"></a><tt class="py-lineno">149</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer.update"></a><div id="Tokenizer.update-def"><a name="L150"></a><tt class="py-lineno">150</tt> <a class="py-toggle" href="#" id="Tokenizer.update-toggle" onclick="return toggle('Tokenizer.update');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#update">update</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-op">**</tt><tt class="py-param">kwargs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer.update-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer.update-expanded"><a name="L151"></a><tt class="py-lineno">151</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L152"></a><tt class="py-lineno">152</tt>  <tt class="py-line"><tt class="py-docstring">        Adjust any settings of the Tokenizer.</tt> </tt>
<a name="L153"></a><tt class="py-lineno">153</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L154"></a><tt class="py-lineno">154</tt>  <tt class="py-line"><tt class="py-docstring">          &gt;&gt;&gt; gettokens.lowercase</tt> </tt>
<a name="L155"></a><tt class="py-lineno">155</tt>  <tt class="py-line"><tt class="py-docstring">          True</tt> </tt>
<a name="L156"></a><tt class="py-lineno">156</tt>  <tt class="py-line"><tt class="py-docstring">          &gt;&gt;&gt; gettokens.phonenumbers</tt> </tt>
<a name="L157"></a><tt class="py-lineno">157</tt>  <tt class="py-line"><tt class="py-docstring">          'PHONENUMBER'</tt> </tt>
<a name="L158"></a><tt class="py-lineno">158</tt>  <tt class="py-line"><tt class="py-docstring">          &gt;&gt;&gt; gettokens.update(phonenumbers='NUMBER', lowercase=False)</tt> </tt>
<a name="L159"></a><tt class="py-lineno">159</tt>  <tt class="py-line"><tt class="py-docstring">          &gt;&gt;&gt; gettokens.lowercase</tt> </tt>
<a name="L160"></a><tt class="py-lineno">160</tt>  <tt class="py-line"><tt class="py-docstring">          False</tt> </tt>
<a name="L161"></a><tt class="py-lineno">161</tt>  <tt class="py-line"><tt class="py-docstring">          &gt;&gt;&gt; gettokens.phonenumbers</tt> </tt>
<a name="L162"></a><tt class="py-lineno">162</tt>  <tt class="py-line"><tt class="py-docstring">          'NUMBER'</tt> </tt>
<a name="L163"></a><tt class="py-lineno">163</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L164"></a><tt class="py-lineno">164</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">keyword</tt> <tt class="py-keyword">in</tt> <tt id="link-35" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-35', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-36" class="py-name"><a title="tweetokenize.Tokenizer.__default_args" class="py-name" href="#" onclick="return doclink('link-36', '__default_args', 'link-1');">__default_args</a></tt><tt class="py-op">:</tt> </tt>
<a name="L165"></a><tt class="py-lineno">165</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">keyword</tt> <tt class="py-keyword">in</tt> <tt class="py-name">kwargs</tt><tt class="py-op">:</tt> </tt>
<a name="L166"></a><tt class="py-lineno">166</tt>  <tt class="py-line">                <tt class="py-name">setattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">keyword</tt><tt class="py-op">,</tt> <tt class="py-name">kwargs</tt><tt class="py-op">[</tt><tt class="py-name">keyword</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
</div><a name="L167"></a><tt class="py-lineno">167</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer._converthtmlentities"></a><div id="Tokenizer._converthtmlentities-def"><a name="L168"></a><tt class="py-lineno">168</tt> <a class="py-toggle" href="#" id="Tokenizer._converthtmlentities-toggle" onclick="return toggle('Tokenizer._converthtmlentities');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#_converthtmlentities">_converthtmlentities</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">msg</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer._converthtmlentities-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer._converthtmlentities-expanded"><a name="L169"></a><tt class="py-lineno">169</tt>  <tt class="py-line">        <tt class="py-keyword">def</tt> <tt class="py-def-name">replace_entities</tt><tt class="py-op">(</tt><tt class="py-param">s</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L170"></a><tt class="py-lineno">170</tt>  <tt class="py-line">            <tt class="py-name">s</tt> <tt class="py-op">=</tt> <tt class="py-name">s</tt><tt class="py-op">.</tt><tt class="py-name">group</tt><tt class="py-op">(</tt><tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> <tt class="py-comment"># remove &amp; and ;</tt> </tt>
<a name="L171"></a><tt class="py-lineno">171</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">s</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt> <tt class="py-op">==</tt> <tt class="py-string">'#'</tt><tt class="py-op">:</tt> </tt>
<a name="L172"></a><tt class="py-lineno">172</tt>  <tt class="py-line">                <tt class="py-keyword">try</tt><tt class="py-op">:</tt> </tt>
<a name="L173"></a><tt class="py-lineno">173</tt>  <tt class="py-line">                    <tt class="py-keyword">return</tt> <tt class="py-name">unichr</tt><tt class="py-op">(</tt><tt class="py-name">int</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">[</tt><tt class="py-number">2</tt><tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">,</tt><tt class="py-number">16</tt><tt class="py-op">)</tt> <tt class="py-keyword">if</tt> <tt class="py-name">s</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> <tt class="py-keyword">in</tt> <tt class="py-string">'xX'</tt> <tt class="py-keyword">else</tt> <tt class="py-name">int</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L174"></a><tt class="py-lineno">174</tt>  <tt class="py-line">                <tt class="py-keyword">except</tt> <tt class="py-name">ValueError</tt><tt class="py-op">:</tt> </tt>
<a name="L175"></a><tt class="py-lineno">175</tt>  <tt class="py-line">                    <tt class="py-keyword">return</tt> <tt class="py-string">'&amp;#'</tt> <tt class="py-op">+</tt> <tt class="py-name">s</tt> <tt class="py-op">+</tt> <tt class="py-string">';'</tt> </tt>
<a name="L176"></a><tt class="py-lineno">176</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L177"></a><tt class="py-lineno">177</tt>  <tt class="py-line">                <tt class="py-keyword">try</tt><tt class="py-op">:</tt> </tt>
<a name="L178"></a><tt class="py-lineno">178</tt>  <tt class="py-line">                    <tt class="py-keyword">return</tt> <tt id="link-37" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-37', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-38" class="py-name"><a title="tweetokenize.Tokenizer.html_entities" class="py-name" href="#" onclick="return doclink('link-38', 'html_entities', 'link-0');">html_entities</a></tt><tt class="py-op">[</tt><tt class="py-name">s</tt><tt class="py-op">]</tt> </tt>
<a name="L179"></a><tt class="py-lineno">179</tt>  <tt class="py-line">                <tt class="py-keyword">except</tt> <tt class="py-name">KeyError</tt><tt class="py-op">:</tt> </tt>
<a name="L180"></a><tt class="py-lineno">180</tt>  <tt class="py-line">                    <tt class="py-keyword">return</tt> <tt class="py-string">'&amp;'</tt> <tt class="py-op">+</tt> <tt class="py-name">s</tt> <tt class="py-op">+</tt> <tt class="py-string">';'</tt> </tt>
</div><a name="L181"></a><tt class="py-lineno">181</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-39" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-39', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-40" class="py-name"><a title="tweetokenize.Tokenizer.html_entities_re" class="py-name" href="#" onclick="return doclink('link-40', 'html_entities_re', 'link-21');">html_entities_re</a></tt><tt class="py-op">.</tt><tt class="py-name">sub</tt><tt class="py-op">(</tt><tt class="py-name">replace_entities</tt><tt class="py-op">,</tt> <tt class="py-name">msg</tt><tt class="py-op">)</tt> </tt>
</div><a name="L182"></a><tt class="py-lineno">182</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer._replacetokens"></a><div id="Tokenizer._replacetokens-def"><a name="L183"></a><tt class="py-lineno">183</tt> <a class="py-toggle" href="#" id="Tokenizer._replacetokens-toggle" onclick="return toggle('Tokenizer._replacetokens');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#_replacetokens">_replacetokens</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">msg</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer._replacetokens-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer._replacetokens-expanded"><a name="L184"></a><tt class="py-lineno">184</tt>  <tt class="py-line">        <tt class="py-name">tokens</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-op">]</tt><tt class="py-op">;</tt> <tt class="py-name">deletion_tokens</tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-string">''</tt><tt class="py-op">,</tt><tt class="py-string">'REMOVE'</tt><tt class="py-op">,</tt><tt class="py-string">'remove'</tt><tt class="py-op">,</tt><tt class="py-string">'DELETE'</tt><tt class="py-op">,</tt><tt class="py-string">'delete'</tt><tt class="py-op">)</tt> </tt>
<a name="L185"></a><tt class="py-lineno">185</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">word</tt> <tt class="py-keyword">in</tt> <tt class="py-name">msg</tt><tt class="py-op">:</tt> </tt>
<a name="L186"></a><tt class="py-lineno">186</tt>  <tt class="py-line">            <tt class="py-name">matching</tt> <tt class="py-op">=</tt> <tt id="link-41" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-41', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-42" class="py-name"><a title="tweetokenize.Tokenizer.word_re" class="py-name" href="#" onclick="return doclink('link-42', 'word_re', 'link-8');">word_re</a></tt><tt class="py-op">.</tt><tt class="py-name">match</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">)</tt> <tt class="py-comment"># 1st check if normal word</tt> </tt>
<a name="L187"></a><tt class="py-lineno">187</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">matching</tt> <tt class="py-keyword">and</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">matching</tt><tt class="py-op">.</tt><tt class="py-name">group</tt><tt class="py-op">(</tt><tt class="py-number">0</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L188"></a><tt class="py-lineno">188</tt>  <tt class="py-line">                <tt class="py-name">tokens</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_cleanword</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L189"></a><tt class="py-lineno">189</tt>  <tt class="py-line">                <tt class="py-keyword">continue</tt> <tt class="py-comment"># don't check rest of conditions</tt> </tt>
<a name="L190"></a><tt class="py-lineno">190</tt>  <tt class="py-line">            <tt class="py-keyword">for</tt> <tt class="py-name">token</tt> <tt class="py-keyword">in</tt> <tt id="link-43" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-43', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-44" class="py-name"><a title="tweetokenize.Tokenizer._token_regexs" class="py-name" href="#" onclick="return doclink('link-44', '_token_regexs', 'link-15');">_token_regexs</a></tt><tt class="py-op">:</tt> <tt class="py-comment"># id &amp; possibly replace tokens</tt> </tt>
<a name="L191"></a><tt class="py-lineno">191</tt>  <tt class="py-line">                <tt class="py-name">regex</tt> <tt class="py-op">=</tt> <tt class="py-name">getattr</tt><tt class="py-op">(</tt><tt id="link-45" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-45', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">,</tt> <tt class="py-string">'%s_re'</tt> <tt class="py-op">%</tt> <tt class="py-name">token</tt><tt class="py-op">)</tt> </tt>
<a name="L192"></a><tt class="py-lineno">192</tt>  <tt class="py-line">                <tt class="py-name">replacementtoken</tt> <tt class="py-op">=</tt> <tt class="py-name">getattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">token</tt><tt class="py-op">)</tt> </tt>
<a name="L193"></a><tt class="py-lineno">193</tt>  <tt class="py-line">                <tt class="py-keyword">if</tt> <tt class="py-name">regex</tt><tt class="py-op">.</tt><tt class="py-name">match</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L194"></a><tt class="py-lineno">194</tt>  <tt class="py-line">                    <tt class="py-keyword">if</tt> <tt class="py-name">replacementtoken</tt><tt class="py-op">:</tt> <tt class="py-comment"># decide if we change it</tt> </tt>
<a name="L195"></a><tt class="py-lineno">195</tt>  <tt class="py-line">                        <tt class="py-name">word</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_unicode</tt><tt class="py-op">(</tt><tt class="py-name">str</tt><tt class="py-op">(</tt><tt class="py-name">replacementtoken</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L196"></a><tt class="py-lineno">196</tt>  <tt class="py-line">                    <tt class="py-keyword">if</tt> <tt class="py-name">replacementtoken</tt> <tt class="py-keyword">not</tt> <tt class="py-keyword">in</tt> <tt class="py-name">deletion_tokens</tt><tt class="py-op">:</tt> </tt>
<a name="L197"></a><tt class="py-lineno">197</tt>  <tt class="py-line">                        <tt class="py-name">tokens</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">)</tt> </tt>
<a name="L198"></a><tt class="py-lineno">198</tt>  <tt class="py-line">                    <tt class="py-keyword">break</tt> </tt>
<a name="L199"></a><tt class="py-lineno">199</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> <tt class="py-comment"># we didn't find a match for any token so far...</tt> </tt>
<a name="L200"></a><tt class="py-lineno">200</tt>  <tt class="py-line">                <tt class="py-keyword">if</tt> <tt id="link-46" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-46', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-47" class="py-name"><a title="tweetokenize.Tokenizer.ellipsis_re" class="py-name" href="#" onclick="return doclink('link-47', 'ellipsis_re', 'link-7');">ellipsis_re</a></tt><tt class="py-op">.</tt><tt class="py-name">match</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L201"></a><tt class="py-lineno">201</tt>  <tt class="py-line">                    <tt class="py-name">tokens</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-string">u"..."</tt><tt class="py-op">)</tt> </tt>
<a name="L202"></a><tt class="py-lineno">202</tt>  <tt class="py-line">                <tt class="py-keyword">else</tt><tt class="py-op">:</tt> <tt class="py-comment"># split into tokens based on emoticons or punctuation</tt> </tt>
<a name="L203"></a><tt class="py-lineno">203</tt>  <tt class="py-line">                    <tt class="py-name">tokens</tt><tt class="py-op">.</tt><tt class="py-name">extend</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_separate_emoticons_punctuation</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L204"></a><tt class="py-lineno">204</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">tokens</tt> </tt>
</div><a name="L205"></a><tt class="py-lineno">205</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer._separate_emoticons_punctuation"></a><div id="Tokenizer._separate_emoticons_punctuation-def"><a name="L206"></a><tt class="py-lineno">206</tt> <a class="py-toggle" href="#" id="Tokenizer._separate_emoticons_punctuation-toggle" onclick="return toggle('Tokenizer._separate_emoticons_punctuation');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#_separate_emoticons_punctuation">_separate_emoticons_punctuation</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">word</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer._separate_emoticons_punctuation-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer._separate_emoticons_punctuation-expanded"><a name="L207"></a><tt class="py-lineno">207</tt>  <tt class="py-line">        <tt class="py-name">newwords</tt><tt class="py-op">=</tt><tt class="py-op">[</tt><tt class="py-op">]</tt><tt class="py-op">;</tt> <tt class="py-name">wordbefore</tt><tt class="py-op">=</tt><tt class="py-string">u""</tt><tt class="py-op">;</tt> <tt class="py-name">i</tt><tt class="py-op">=</tt><tt class="py-number">0</tt> </tt>
<a name="L208"></a><tt class="py-lineno">208</tt>  <tt class="py-line">        <tt class="py-keyword">def</tt> <tt class="py-def-name">possibly_append_and_reset</tt><tt class="py-op">(</tt><tt class="py-param">w</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L209"></a><tt class="py-lineno">209</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">w</tt><tt class="py-op">:</tt> </tt>
<a name="L210"></a><tt class="py-lineno">210</tt>  <tt class="py-line">                <tt class="py-name">newwords</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_cleanword</tt><tt class="py-op">(</tt><tt class="py-name">w</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L211"></a><tt class="py-lineno">211</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-string">u""</tt> </tt>
</div><a name="L212"></a><tt class="py-lineno">212</tt>  <tt class="py-line">        <tt class="py-keyword">while</tt> <tt class="py-name">i</tt> <tt class="py-op">&lt;</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L213"></a><tt class="py-lineno">213</tt>  <tt class="py-line">            <tt class="py-comment"># greedily check for emoticons in this word</tt> </tt>
<a name="L214"></a><tt class="py-lineno">214</tt>  <tt class="py-line">            <tt class="py-keyword">for</tt> <tt class="py-name">l</tt> <tt class="py-keyword">in</tt> <tt class="py-name">range</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_maxlenemo</tt><tt class="py-op">,</tt> <tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L215"></a><tt class="py-lineno">215</tt>  <tt class="py-line">                <tt class="py-keyword">if</tt> <tt class="py-name">word</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">:</tt><tt class="py-name">i</tt><tt class="py-op">+</tt><tt class="py-name">l</tt><tt class="py-op">]</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_emoticons</tt> <tt class="py-keyword">or</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_isemoji</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">:</tt><tt class="py-name">i</tt><tt class="py-op">+</tt><tt class="py-name">l</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L216"></a><tt class="py-lineno">216</tt>  <tt class="py-line">                    <tt class="py-name">wordbefore</tt> <tt class="py-op">=</tt> <tt class="py-name">possibly_append_and_reset</tt><tt class="py-op">(</tt><tt class="py-name">wordbefore</tt><tt class="py-op">)</tt> </tt>
<a name="L217"></a><tt class="py-lineno">217</tt>  <tt class="py-line">                    <tt class="py-name">newwords</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">:</tt><tt class="py-name">i</tt><tt class="py-op">+</tt><tt class="py-name">l</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L218"></a><tt class="py-lineno">218</tt>  <tt class="py-line">                    <tt class="py-name">i</tt><tt class="py-op">+=</tt><tt class="py-name">l</tt> </tt>
<a name="L219"></a><tt class="py-lineno">219</tt>  <tt class="py-line">                    <tt class="py-keyword">break</tt> </tt>
<a name="L220"></a><tt class="py-lineno">220</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> <tt class="py-comment"># its safe to break up any punctuation not part of emoticons</tt> </tt>
<a name="L221"></a><tt class="py-lineno">221</tt>  <tt class="py-line">                <tt class="py-keyword">if</tt> <tt class="py-name">word</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt> <tt class="py-keyword">in</tt> <tt id="link-48" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-48', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-49" class="py-name"><a title="tweetokenize.Tokenizer.punctuation" class="py-name" href="#" onclick="return doclink('link-49', 'punctuation', 'link-24');">punctuation</a></tt><tt class="py-op">:</tt> </tt>
<a name="L222"></a><tt class="py-lineno">222</tt>  <tt class="py-line">                    <tt class="py-name">wordbefore</tt> <tt class="py-op">=</tt> <tt class="py-name">possibly_append_and_reset</tt><tt class="py-op">(</tt><tt class="py-name">wordbefore</tt><tt class="py-op">)</tt> </tt>
<a name="L223"></a><tt class="py-lineno">223</tt>  <tt class="py-line">                    <tt class="py-name">newwords</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L224"></a><tt class="py-lineno">224</tt>  <tt class="py-line">                <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L225"></a><tt class="py-lineno">225</tt>  <tt class="py-line">                    <tt class="py-name">wordbefore</tt> <tt class="py-op">+=</tt> <tt class="py-name">word</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt> </tt>
<a name="L226"></a><tt class="py-lineno">226</tt>  <tt class="py-line">                <tt class="py-name">i</tt><tt class="py-op">+=</tt><tt class="py-number">1</tt> </tt>
<a name="L227"></a><tt class="py-lineno">227</tt>  <tt class="py-line">        <tt class="py-comment"># possible ending of word which wasn't emoticon or punctuation</tt> </tt>
<a name="L228"></a><tt class="py-lineno">228</tt>  <tt class="py-line">        <tt class="py-name">possibly_append_and_reset</tt><tt class="py-op">(</tt><tt class="py-name">wordbefore</tt><tt class="py-op">)</tt> </tt>
<a name="L229"></a><tt class="py-lineno">229</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">newwords</tt> </tt>
</div><a name="L230"></a><tt class="py-lineno">230</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer._isemoji"></a><div id="Tokenizer._isemoji-def"><a name="L231"></a><tt class="py-lineno">231</tt> <a class="py-toggle" href="#" id="Tokenizer._isemoji-toggle" onclick="return toggle('Tokenizer._isemoji');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#_isemoji">_isemoji</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">s</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer._isemoji-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer._isemoji-expanded"><a name="L232"></a><tt class="py-lineno">232</tt>  <tt class="py-line">        <tt class="py-name">emoji_ranges</tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-string">u'&#55356;&#57088;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55357;&#56831;'</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-op">(</tt><tt class="py-string">u'&#55357;&#56832;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55357;&#56911;'</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-op">(</tt><tt class="py-string">u'&#55357;&#56960;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55357;&#57029;'</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-op">(</tt><tt class="py-string">u'&#9728;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#9983;'</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-op">(</tt><tt class="py-string">u'&#55356;&#56688;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55356;&#56730;'</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L233"></a><tt class="py-lineno">233</tt>  <tt class="py-line">        <tt class="py-name">emoji_flags</tt> <tt class="py-op">=</tt>  <tt class="py-name">set</tt><tt class="py-op">(</tt><tt class="py-op">[</tt><tt class="py-string">u'&#55356;&#56815;&#55356;&#56821;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55356;&#56816;&#55356;&#56823;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55356;&#56809;&#55356;&#56810;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55356;&#56808;&#55356;&#56819;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55356;&#56826;&#55356;&#56824;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55356;&#56811;&#55356;&#56823;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55356;&#56810;&#55356;&#56824;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55356;&#56814;&#55356;&#56825;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55356;&#56823;&#55356;&#56826;'</tt><tt class="py-op">,</tt> <tt class="py-string">u'&#55356;&#56812;&#55356;&#56807;'</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L234"></a><tt class="py-lineno">234</tt>  <tt class="py-line">        <tt class="py-name">check_emoji</tt> <tt class="py-op">=</tt> <tt class="py-keyword">lambda</tt> <tt class="py-name">given</tt><tt class="py-op">:</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">given</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-string">u'&#55357;&#56489;'</tt><tt class="py-op">)</tt> <tt class="py-keyword">and</tt> <tt class="py-name">any</tt><tt class="py-op">(</tt><tt class="py-name">e</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt> <tt class="py-op">&lt;=</tt> <tt class="py-name">given</tt> <tt class="py-op">&lt;=</tt> <tt class="py-name">e</tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> <tt class="py-keyword">for</tt> <tt class="py-name">e</tt> <tt class="py-keyword">in</tt> <tt class="py-name">emoji_ranges</tt><tt class="py-op">)</tt> </tt>
<a name="L235"></a><tt class="py-lineno">235</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">check_emoji</tt><tt class="py-op">(</tt><tt class="py-name">s</tt><tt class="py-op">)</tt> <tt class="py-keyword">or</tt> <tt class="py-name">s</tt> <tt class="py-keyword">in</tt> <tt class="py-name">emoji_flags</tt> </tt>
</div><a name="L236"></a><tt class="py-lineno">236</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer._cleanword"></a><div id="Tokenizer._cleanword-def"><a name="L237"></a><tt class="py-lineno">237</tt> <a class="py-toggle" href="#" id="Tokenizer._cleanword-toggle" onclick="return toggle('Tokenizer._cleanword');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#_cleanword">_cleanword</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">word</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer._cleanword-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer._cleanword-expanded"><a name="L238"></a><tt class="py-lineno">238</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">normalize</tt><tt class="py-op">:</tt> <tt class="py-comment"># replace characters with &gt;=3 alphabetic repeating</tt> </tt>
<a name="L239"></a><tt class="py-lineno">239</tt>  <tt class="py-line">            <tt class="py-name">word</tt> <tt class="py-op">=</tt> <tt id="link-50" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-50', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-51" class="py-name"><a title="tweetokenize.Tokenizer.repeating_re" class="py-name" href="#" onclick="return doclink('link-51', 'repeating_re', 'link-22');">repeating_re</a></tt><tt class="py-op">.</tt><tt class="py-name">sub</tt><tt class="py-op">(</tt><tt class="py-string">r"\1"</tt><tt class="py-op">*</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">normalize</tt><tt class="py-op">,</tt> <tt class="py-name">word</tt><tt class="py-op">)</tt> </tt>
<a name="L240"></a><tt class="py-lineno">240</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">lowercase</tt> <tt class="py-keyword">and</tt> <tt class="py-op">(</tt><tt class="py-keyword">not</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">allcapskeep</tt> <tt class="py-keyword">or</tt> <tt class="py-keyword">not</tt> <tt class="py-name">word</tt><tt class="py-op">.</tt><tt class="py-name">isupper</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L241"></a><tt class="py-lineno">241</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">word</tt><tt class="py-op">.</tt><tt class="py-name">lower</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L242"></a><tt class="py-lineno">242</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">word</tt> </tt>
</div><a name="L243"></a><tt class="py-lineno">243</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer._unicode"></a><div id="Tokenizer._unicode-def"><a name="L244"></a><tt class="py-lineno">244</tt> <a class="py-toggle" href="#" id="Tokenizer._unicode-toggle" onclick="return toggle('Tokenizer._unicode');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#_unicode">_unicode</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">word</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer._unicode-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer._unicode-expanded"><a name="L245"></a><tt class="py-lineno">245</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">,</tt> <tt class="py-name">unicode</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L246"></a><tt class="py-lineno">246</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">word</tt> </tt>
<a name="L247"></a><tt class="py-lineno">247</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">unicode</tt><tt class="py-op">(</tt><tt class="py-name">word</tt><tt class="py-op">,</tt> <tt class="py-name">encoding</tt><tt class="py-op">=</tt><tt class="py-string">'utf-8'</tt><tt class="py-op">)</tt> </tt>
</div><a name="L248"></a><tt class="py-lineno">248</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer.tokenize"></a><div id="Tokenizer.tokenize-def"><a name="L249"></a><tt class="py-lineno">249</tt> <a class="py-toggle" href="#" id="Tokenizer.tokenize-toggle" onclick="return toggle('Tokenizer.tokenize');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#tokenize">tokenize</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">message</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer.tokenize-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer.tokenize-expanded"><a name="L250"></a><tt class="py-lineno">250</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L251"></a><tt class="py-lineno">251</tt>  <tt class="py-line"><tt class="py-docstring">        Tokenize the given string into a list of strings representing the </tt> </tt>
<a name="L252"></a><tt class="py-lineno">252</tt>  <tt class="py-line"><tt class="py-docstring">        constituent words of the message.</tt> </tt>
<a name="L253"></a><tt class="py-lineno">253</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L254"></a><tt class="py-lineno">254</tt>  <tt class="py-line"><tt class="py-docstring">        @rtype: C{list} of C{str}</tt> </tt>
<a name="L255"></a><tt class="py-lineno">255</tt>  <tt class="py-line"><tt class="py-docstring">        @return: The tokenization of the message.</tt> </tt>
<a name="L256"></a><tt class="py-lineno">256</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L257"></a><tt class="py-lineno">257</tt>  <tt class="py-line"><tt class="py-docstring">        @type message: C{str}</tt> </tt>
<a name="L258"></a><tt class="py-lineno">258</tt>  <tt class="py-line"><tt class="py-docstring">        @param message: The string representation of the message.</tt> </tt>
<a name="L259"></a><tt class="py-lineno">259</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L260"></a><tt class="py-lineno">260</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">message</tt><tt class="py-op">,</tt> <tt class="py-name">basestring</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L261"></a><tt class="py-lineno">261</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt id="link-52" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-52', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-53" class="py-name" targets="Class tweetokenize.Tokenizer.TokenizerException=tweetokenize.Tokenizer.TokenizerException-class.html"><a title="tweetokenize.Tokenizer.TokenizerException" class="py-name" href="#" onclick="return doclink('link-53', 'TokenizerException', 'link-53');">TokenizerException</a></tt><tt class="py-op">(</tt><tt class="py-string">'cannot tokenize non-string, %s'</tt> </tt>
<a name="L262"></a><tt class="py-lineno">262</tt>  <tt class="py-line">            <tt class="py-op">%</tt> <tt class="py-name">repr</tt><tt class="py-op">(</tt><tt class="py-name">message</tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt><tt class="py-op">.</tt><tt class="py-name">__name__</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L263"></a><tt class="py-lineno">263</tt>  <tt class="py-line">        <tt class="py-name">message</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_converthtmlentities</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_unicode</tt><tt class="py-op">(</tt><tt class="py-name">message</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L264"></a><tt class="py-lineno">264</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">ignorequotes</tt><tt class="py-op">:</tt> </tt>
<a name="L265"></a><tt class="py-lineno">265</tt>  <tt class="py-line">            <tt class="py-name">message</tt> <tt class="py-op">=</tt> <tt id="link-54" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-54', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-55" class="py-name"><a title="tweetokenize.Tokenizer.quotes_re" class="py-name" href="#" onclick="return doclink('link-55', 'quotes_re', 'link-26');">quotes_re</a></tt><tt class="py-op">.</tt><tt class="py-name">sub</tt><tt class="py-op">(</tt><tt class="py-string">" "</tt><tt class="py-op">,</tt> <tt class="py-name">message</tt><tt class="py-op">)</tt> </tt>
<a name="L266"></a><tt class="py-lineno">266</tt>  <tt class="py-line">        <tt class="py-name">message</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_replacetokens</tt><tt class="py-op">(</tt><tt id="link-56" class="py-name"><a title="tweetokenize.Tokenizer" class="py-name" href="#" onclick="return doclink('link-56', 'Tokenizer', 'link-28');">Tokenizer</a></tt><tt class="py-op">.</tt><tt id="link-57" class="py-name"><a title="tweetokenize.Tokenizer.tokenize_re" class="py-name" href="#" onclick="return doclink('link-57', 'tokenize_re', 'link-16');">tokenize_re</a></tt><tt class="py-op">.</tt><tt class="py-name">findall</tt><tt class="py-op">(</tt><tt class="py-name">message</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L267"></a><tt class="py-lineno">267</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">ignorestopwords</tt><tt class="py-op">:</tt> </tt>
<a name="L268"></a><tt class="py-lineno">268</tt>  <tt class="py-line">            <tt class="py-name">message</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-name">word</tt> <tt class="py-keyword">for</tt> <tt class="py-name">word</tt> <tt class="py-keyword">in</tt> <tt class="py-name">message</tt> <tt class="py-keyword">if</tt> <tt class="py-name">word</tt> <tt class="py-keyword">not</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_stopwords</tt><tt class="py-op">]</tt> </tt>
<a name="L269"></a><tt class="py-lineno">269</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">message</tt> </tt>
</div><a name="L270"></a><tt class="py-lineno">270</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer.emoticons"></a><div id="Tokenizer.emoticons-def"><a name="L271"></a><tt class="py-lineno">271</tt> <a class="py-toggle" href="#" id="Tokenizer.emoticons-toggle" onclick="return toggle('Tokenizer.emoticons');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#emoticons">emoticons</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">iterable</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-param">filename</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer.emoticons-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer.emoticons-expanded"><a name="L272"></a><tt class="py-lineno">272</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L273"></a><tt class="py-lineno">273</tt>  <tt class="py-line"><tt class="py-docstring">        Consumes an iterable of emoticons that the tokenizer will tokenize on. </tt> </tt>
<a name="L274"></a><tt class="py-lineno">274</tt>  <tt class="py-line"><tt class="py-docstring">        Allows for user-specified set of emoticons to be recognized.</tt> </tt>
<a name="L275"></a><tt class="py-lineno">275</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L276"></a><tt class="py-lineno">276</tt>  <tt class="py-line"><tt class="py-docstring">        @param iterable: Object capable of iteration, providing emoticon </tt> </tt>
<a name="L277"></a><tt class="py-lineno">277</tt>  <tt class="py-line"><tt class="py-docstring">            strings.</tt> </tt>
<a name="L278"></a><tt class="py-lineno">278</tt>  <tt class="py-line"><tt class="py-docstring">        @type filename: C{str}</tt> </tt>
<a name="L279"></a><tt class="py-lineno">279</tt>  <tt class="py-line"><tt class="py-docstring">        @param filename: Path to the file containing emoticons delimited by </tt> </tt>
<a name="L280"></a><tt class="py-lineno">280</tt>  <tt class="py-line"><tt class="py-docstring">            new lines. Strips trailing whitespace and skips blank lines.</tt> </tt>
<a name="L281"></a><tt class="py-lineno">281</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L282"></a><tt class="py-lineno">282</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_emoticons</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_collectset</tt><tt class="py-op">(</tt><tt class="py-name">iterable</tt><tt class="py-op">,</tt> <tt class="py-name">filename</tt><tt class="py-op">)</tt> </tt>
<a name="L283"></a><tt class="py-lineno">283</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_maxlenemo</tt> <tt class="py-op">=</tt> <tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">max</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_emoticons</tt><tt class="py-op">,</tt> <tt class="py-name">key</tt><tt class="py-op">=</tt><tt class="py-keyword">lambda</tt> <tt class="py-name">x</tt><tt class="py-op">:</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L284"></a><tt class="py-lineno">284</tt>  <tt class="py-line">        <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-string">u'&#55356;&#56808;&#55356;&#56819;'</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-string">u'&#55357;&#56459;'</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L285"></a><tt class="py-lineno">285</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer.stopwords"></a><div id="Tokenizer.stopwords-def"><a name="L286"></a><tt class="py-lineno">286</tt> <a class="py-toggle" href="#" id="Tokenizer.stopwords-toggle" onclick="return toggle('Tokenizer.stopwords');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#stopwords">stopwords</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">iterable</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-param">filename</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer.stopwords-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer.stopwords-expanded"><a name="L287"></a><tt class="py-lineno">287</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L288"></a><tt class="py-lineno">288</tt>  <tt class="py-line"><tt class="py-docstring">        Consumes an iterable of stopwords that the tokenizer will ignore if the </tt> </tt>
<a name="L289"></a><tt class="py-lineno">289</tt>  <tt class="py-line"><tt class="py-docstring">        stopwords setting is C{True}. The default set is taken from NLTK's </tt> </tt>
<a name="L290"></a><tt class="py-lineno">290</tt>  <tt class="py-line"><tt class="py-docstring">        english list.</tt> </tt>
<a name="L291"></a><tt class="py-lineno">291</tt>  <tt class="py-line"><tt class="py-docstring">        </tt> </tt>
<a name="L292"></a><tt class="py-lineno">292</tt>  <tt class="py-line"><tt class="py-docstring">        @param iterable: Object capable of iteration, providing stopword </tt> </tt>
<a name="L293"></a><tt class="py-lineno">293</tt>  <tt class="py-line"><tt class="py-docstring">            strings.</tt> </tt>
<a name="L294"></a><tt class="py-lineno">294</tt>  <tt class="py-line"><tt class="py-docstring">        @type filename: C{str}</tt> </tt>
<a name="L295"></a><tt class="py-lineno">295</tt>  <tt class="py-line"><tt class="py-docstring">        @param filename: Path to the file containing stopwords delimited by </tt> </tt>
<a name="L296"></a><tt class="py-lineno">296</tt>  <tt class="py-line"><tt class="py-docstring">            new lines. Strips trailing whitespace and skips blank lines.</tt> </tt>
<a name="L297"></a><tt class="py-lineno">297</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L298"></a><tt class="py-lineno">298</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_stopwords</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_collectset</tt><tt class="py-op">(</tt><tt class="py-name">iterable</tt><tt class="py-op">,</tt> <tt class="py-name">filename</tt><tt class="py-op">)</tt> </tt>
</div><a name="L299"></a><tt class="py-lineno">299</tt>  <tt class="py-line">     </tt>
<a name="Tokenizer._collectset"></a><div id="Tokenizer._collectset-def"><a name="L300"></a><tt class="py-lineno">300</tt> <a class="py-toggle" href="#" id="Tokenizer._collectset-toggle" onclick="return toggle('Tokenizer._collectset');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="tweetokenize.Tokenizer-class.html#_collectset">_collectset</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">iterable</tt><tt class="py-op">,</tt> <tt class="py-param">filename</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Tokenizer._collectset-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="Tokenizer._collectset-expanded"><a name="L301"></a><tt class="py-lineno">301</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">filename</tt><tt class="py-op">:</tt> </tt>
<a name="L302"></a><tt class="py-lineno">302</tt>  <tt class="py-line">            <tt class="py-keyword">with</tt> <tt class="py-name">open</tt><tt class="py-op">(</tt><tt class="py-name">filename</tt><tt class="py-op">,</tt> <tt class="py-string">"r"</tt><tt class="py-op">)</tt> <tt class="py-keyword">as</tt> <tt class="py-name">f</tt><tt class="py-op">:</tt> </tt>
<a name="L303"></a><tt class="py-lineno">303</tt>  <tt class="py-line">                <tt class="py-name">iterable</tt> <tt class="py-op">=</tt> <tt class="py-name">set</tt><tt class="py-op">(</tt><tt class="py-name">l</tt><tt class="py-op">.</tt><tt class="py-name">rstrip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">l</tt> <tt class="py-keyword">in</tt> <tt class="py-name">f</tt><tt class="py-op">)</tt> </tt>
<a name="L304"></a><tt class="py-lineno">304</tt>  <tt class="py-line">                <tt class="py-name">iterable</tt><tt class="py-op">.</tt><tt class="py-name">discard</tt><tt class="py-op">(</tt><tt class="py-string">''</tt><tt class="py-op">)</tt> </tt>
<a name="L305"></a><tt class="py-lineno">305</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">set</tt><tt class="py-op">(</tt><tt class="py-name">imap</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_unicode</tt><tt class="py-op">,</tt> <tt class="py-name">iterable</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L306"></a><tt class="py-lineno">306</tt>  <tt class="py-line"> </tt><script type="text/javascript">
<!--
expandto(location.href);
// -->
</script>
</pre>
<br />
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th bgcolor="#70b0f0" class="navbar-select"
          >&nbsp;&nbsp;&nbsp;Home&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

      <th class="navbar" width="100%"></th>
  </tr>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="100%%">
  <tr>
    <td align="left" class="footer">
    Generated by Epydoc 3.0.1 on Mon May 20 02:41:07 2013
    </td>
    <td align="right" class="footer">
      <a target="mainFrame" href="http://epydoc.sourceforge.net"
        >http://epydoc.sourceforge.net</a>
    </td>
  </tr>
</table>

<script type="text/javascript">
  <!--
  // Private objects are initially displayed (because if
  // javascript is turned off then we want them to be
  // visible); but by default, we want to hide them.  So hide
  // them unless we have a cookie that says to show them.
  checkCookie();
  // -->
</script>
</body>
</html>
